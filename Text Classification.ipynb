{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Table of Contents</a></span></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction<a class=\"anchor\" id=\"Introduction\"></a></a></span></li><li><span><a href=\"#Rule-based-systems\" data-toc-modified-id=\"Rule-based-systems-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Rule-based systems<a class=\"anchor\" id=\"rule\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Machine-Learning-based-systems\" data-toc-modified-id=\"Machine-Learning-based-systems-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Machine Learning based systems<a class=\"anchor\" id=\"ml\"></a></a></span></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Naive Bayes<a class=\"anchor\" id=\"nb\"></a></a></span></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Support Vector Machine<a class=\"anchor\" id=\"svm\"></a></a></span></li><li><span><a href=\"#Deep-learning\" data-toc-modified-id=\"Deep-learning-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Deep learning<a class=\"anchor\" id=\"Dl\"></a></a></span></li></ul></li><li><span><a href=\"#Hybrid-systems\" data-toc-modified-id=\"Hybrid-systems-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Hybrid systems<a class=\"anchor\" id=\"Hybrid\"></a></a></span></li><li><span><a href=\"#Application-areas\" data-toc-modified-id=\"Application-areas-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Application areas<a class=\"anchor\" id=\"application\"></a></a></span></li><li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Implementation<a class=\"anchor\" id=\"implementation\"></a></a></span></li><li><span><a href=\"#Prediction\" data-toc-modified-id=\"Prediction-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Prediction<a class=\"anchor\" id=\"prediction\"></a></a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "   1. [Introduction](#Introduction)\n",
    "   2. [Rule-based systems](#rule)\n",
    "   3. [Machine Learning based systems](#ml)\n",
    "       1. [Naive Bayes](#nb)\n",
    "       2. [SVM](#svm)\n",
    "       3. [Deep Learning](#Dl)\n",
    "   4. [Hybrid Systems](#hybrid)\n",
    "   5. [Applications](#application)\n",
    "   5. [Implementation](#implementation)\n",
    "   6. [Prediction](#prediction)\n",
    "         \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction<a class=\"anchor\" id=\"Introduction\"></a>\n",
    "Text classification is the process of assigning tags or categories to text according to its content. It’s one of the fundamental tasks in Natural Language Processing (NLP) with broad applications such as sentiment analysis, topic labeling, spam detection, and intent detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "![Text Classification](textClassificationExample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many approaches to automatic text classification, which can be grouped into three different types of systems:\n",
    "   * Rule-based systems\n",
    "   * Machine Learning based systems\n",
    "   * Hybrid systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based systems<a class=\"anchor\" id=\"rule\"></a>\n",
    "Rule-based approach is the most simplest way of doing text classification. The pre-requisite of this includes having a good domain knowledge to set the right linguistic rules to categorize the data. Each rule consists of a pattern and a corresponding predicted category.\n",
    "\n",
    "Say that you want to classify news articles into 2 groups, namely, Sports and Politics. First, you’ll need to define two lists of words that characterize each group (e.g. words related to sports such as football, basketball, LeBron James, etc., and words related to politics such as Donald Trump, Hillary Clinton, Putin, etc.). Next, when you want to classify a new incoming text, you’ll need to count the number of sport-related words that appear in the text and do the same for politics-related words. If the number of sport-related word appearances is greater than the number of politics-related word count, then the text is classified as sports and vice versa.\n",
    "\n",
    "Rule-based systems are human comprehensible and can be improved over time. This method is not scalable and requires a lot of domain-expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning based systems<a class=\"anchor\" id=\"ml\"></a>\n",
    "There are a lot of machine learning algorithms that can be used to do text classification. Few among them are:\n",
    "   * Naive Bayes\n",
    "   * SVM\n",
    "   * Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes<a class=\"anchor\" id=\"nb\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilistic model of naive Bayes classifiers is based on Bayes’ theorem, and the adjective naive comes from the assumption that the features in a dataset are mutually independent. Naive bayes simplifies the calculation of probabilities by assuming that the probability of each attribute belonging to a given class value is independent of all other attributes. This is a strong assumption but results in a fast and effective method.The probability of a class value given a value of an attribute is called the conditional probability. By multiplying the conditional probabilities together for each attribute for a given class value, we have a probability of a data instance belonging to that class.\n",
    "\n",
    "To make a prediction we can calculate probabilities of the instance belonging to each class and select the class value with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine<a class=\"anchor\" id=\"svm\"></a>\n",
    "This algorithm works by segregating the categories of intent by drawing a line or a hyperplane that divides the space into two subspaces. According to the SVM algorithm we find the points closest to the line from both the classes.These points are called support vectors. Now, we compute the distance between the line and the support vectors. This distance is called the margin. The margin is supposed to be maximum. The hyperplane for which the margin is maximum is the optimal hyperplane.\n",
    "SVM is mostly used for binary classification. Binary classification is one in which there are only two possible outcomes or intents.SVM for multi class can also be implemented but requires us to run a lot of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SVM](svm.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning<a class=\"anchor\" id=\"Dl\"></a>\n",
    "The important deep learning architectures that can be used for text classification are Convolutional Neural Networks and Recurrent Neural Networks. Naive Bayes and Support Vector Machine run fine with lesser data also but neural networks require a lot of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid systems<a class=\"anchor\" id=\"Hybrid\"></a>\n",
    "The hybrid systems as the name suggests are a combination of machine learning and a rule-based systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application areas<a class=\"anchor\" id=\"application\"></a>\n",
    "   * Customer Service\n",
    "       * Monitoring agent's interactions\n",
    "       *  Improve customer experience and satisfaction incorporating sentiment analysis\n",
    "   * Marketing\n",
    "       * Enhance personalization experience\n",
    "       * Lead score accuracy improvement\n",
    "   * Fraud\n",
    "       * Real-time indexing of violations within conversations, reducing fines for non-compliance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation<a class=\"anchor\" id=\"implementation\"></a>\n",
    "The concepts learned now can be implemented by taking a dummy data and running the models. An e-commerce is selling fine foods. Let us find the sentiment of the reviews given by the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\",index_col=False)\n",
    "data=data.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product arrive label jumbo salt peanuts peanut...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>look secret ingredient robitussin believe find...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get wild hair taffy order five pound bag taffy...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Score\n",
       "0  product arrive label jumbo salt peanuts peanut...  negative\n",
       "1  confection around centuries light pillowy citr...  positive\n",
       "2  look secret ingredient robitussin believe find...  negative\n",
       "3  great taffy great price wide assortment yummy ...  positive\n",
       "4  get wild hair taffy order five pound bag taffy...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are going to use is already pre-processed. The pre-processing steps are beyond the scope of this notebook. \n",
    "The columns are:\n",
    "   * Score - The tag saying if the review is positive or negative\n",
    "   * Text - The review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Precision\", \"Recall\"])\n",
    "all_results = []\n",
    "report = None\n",
    "# function to get the model stats like precision, recall\n",
    "\n",
    "def model_stats(predicted, actual):\n",
    "    global report\n",
    "    report = pd.DataFrame(list(precision_recall_fscore_support(actual, predicted)),\n",
    "                          index=['Precision', 'Recall', 'F1-score', 'Support']).T\n",
    "\n",
    "    # Now add the 'Avg/Total' row\n",
    "    report.loc['Avg', :] = (precision_recall_fscore_support(actual, predicted, average='micro'))\n",
    "    report.loc['Avg', 'Support'] = report['Support'].sum()\n",
    "    report = report.iloc[:, 0:-1]\n",
    "    print(report)\n",
    "\n",
    "#function to train\n",
    "def train(data, textColumn, intentColum):\n",
    "    x= textColumn\n",
    "    y= intentColum\n",
    "    # Create Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[x], data[y], test_size=0.33, random_state=42)\n",
    "\n",
    "    X_train = X_train.astype(\"str\")\n",
    "    y_train = y_train.astype(\"str\")\n",
    "    X_test = X_test.astype(\"str\")\n",
    "    y_test = y_test.astype(\"str\")\n",
    "\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [0.1, 1, 5, 10]},\n",
    "                        {'kernel': ['linear'], 'C': [0.1, 1, 5, 10]}]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(C=1, probability=True, class_weight='balanced'), param_grid=tuned_parameters, cv=2,\n",
    "                             verbose=1)\n",
    "    svc = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1, 2), stop_words='english')), ('clf', estimator), ])\n",
    "\n",
    "    svc = svc.fit(X_train, y_train)\n",
    "    predicted = svc.predict(X_test)\n",
    "\n",
    "    model_stats(predicted, y_test)\n",
    "    save_model(\"./svm_models\", svc, \"sklearn\")\n",
    "    return svc\n",
    "\n",
    "def save_model(directory, model, lib=\"sklearn\"):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    modelname = None\n",
    "\n",
    "    # Save model to file\n",
    "    if lib == \"sklearn\":\n",
    "        modelname = os.path.join(directory, 'model' + str(int(time.time())) + '.pkl')\n",
    "        joblib.dump(model, modelname)\n",
    "    if lib == \"keras\":\n",
    "        modelname = os.path.join(directory, 'model' + str(int(time.time())) + '.h5')\n",
    "        model.save(modelname)\n",
    "    print(\"Trained model saved in : \", modelname)\n",
    "\n",
    "    # Function to predict\n",
    "def predict(train_file, content, modelname):\n",
    "    svc = joblib.load(modelname)\n",
    "    predicted = svc.predict([content])\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Precision    Recall  F1-score\n",
      "0     0.794595  0.567568  0.662162\n",
      "1     0.923549  0.972682  0.947479\n",
      "Avg   0.909091  0.909091  0.909091\n",
      "Trained model saved in :  ./svm_models/model1557839338.pkl\n"
     ]
    }
   ],
   "source": [
    "svmModel = train(data=data,intentColum=\"Score\",textColumn=\"Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction<a class=\"anchor\" id=\"prediction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excite find nana line glutenfree cookies try varieties offer various flavor style cookies favorite find individually package cookies large round ones way heavy one meal end split two snack pack cookies perfect size little snack keep purse understand reviewers might like cookies healthy taste might object texture berry crystals happen like berry crystals nice eat cookie nt feel dietary guilt great hearty cookie go well coffee tea also gluten intolerant never negative reaction cookies whatsoever opinion good product however natural nt preservatives faster item ship package better notice nana cookies become dry longer keep around even seal probably good idea try product buy case notice people either seem love hate nana cookies'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Text.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmPredict = predict(test,content=test.Text.iloc[1],modelname=\"./svm_models/model1557839338.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other machine learning models can be implemented similarly to SVM. But deep learning is computationally very heavy and requires huge RAM to run and hence those models are not implemented here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
